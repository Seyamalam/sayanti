\documentclass{sn-jnl}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[title]{appendix}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{manyfoot}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pgfplots}

\pgfplotsset{compat=1.18}
\usetikzlibrary{shapes.geometric, arrows, positioning, fit, backgrounds, calc}

\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

\begin{document}

\title[Imbalance-Aware Explainable Fraud Detection]{Imbalance-Calibrated Explainable AI for Financial Fraud Detection: Investigating the Difficulty of Regulatory Compliance}

\author*[1]{Touhidul Alam Seyam}
\email{touhidulalam@bgctub.ac.bd}

\author[1]{Sayanti Deb}

\affil*[1]{\orgdiv{Department of Computer Science and Engineering}, \orgname{BGC Trust University Bangladesh}, \orgaddress{\city{Chattogram}, \country{Bangladesh}}}

\abstract{
Financial fraud detection presents a critical challenge at the intersection of machine learning performance and regulatory interpretability. While modern machine learning models achieve exceptional detection accuracy, their "black-box" nature conflicts with financial regulations requiring explainability. This challenge is further compounded by extreme class imbalance, where fraud cases constitute only ~0.39\% of transactions. Traditional explainable AI (XAI) methods exhibit systematic biases when applied to such imbalanced datasets, drastically distorting causal relationships by inflating the importance of generic demographic features over direct financial indicators. We propose a novel framework called Imbalance-Aware Explainable Fraud Detection (IAE-FD) comprising three components: (1) Imbalance-Calibrated SHAP (IC-SHAP), which uses a balanced background sampling strategy to correct explanation bias without destroying normal baseline contrast; (2) Continuous Counterfactual Optimizer (CC-Opt), which attempts to produce actionable explanations satisfying GDPR and ECOA requirements through L1-norm continuous optimization and structural constraints; and (3) Explanation Quality Auditor (EQA), which systematically evaluates explanation reliability in probability space. Experiments on a dataset of 555,719 credit card transactions using strict Out-Of-Time (OOT) validation demonstrate that our framework achieves high realistic AUC-ROC while maintaining explanation stability and fidelity. Critically, IC-SHAP corrects explanation bias by elevating transaction amount (\textit{amt}) to near-parity with categorical factors, closing an artificial 29\% importance gap caused by standard SHAP's biased background distribution. Counterfactual explanations successfully cross decision boundaries, achieving a 100\% success rate, but our analysis reveals that escaping a high-confidence fraud classification requires modifications to an average of 14.6 features. This presents a fundamental challenge to regulatory mandates that assume actionable recourse is strictly achievable in high-dimensional financial models.
}

\keywords{Explainable AI, Fraud Detection, Class Imbalance, SHAP, Counterfactual Explanations, Out-Of-Time Validation}

\maketitle

\section{Introduction}\label{sec1}

The rapid digitization of financial services has precipitated a corresponding escalation in sophisticated fraudulent activities. While machine learning (ML) models, particularly gradient boosting ensembles and deep neural networks, have demonstrated exceptional capability in identifying complex fraud patterns \cite{chen2016xgboost, roy2018deep}, their deployment in highly regulated environments like finance faces a fundamental paradox: the most accurate models are often the most opaque. This structural opacity acts as a significant limitation.

This opacity directly conflicts with evolving global regulatory frameworks. The General Data Protection Regulation (GDPR) in the European Union mandates a "right to explanation" for automated decisions, while the Equal Credit Opportunity Act (ECOA) in the United States requires financial institutions to provide actionable reasons for adverse actions. Furthermore, model governance standards set by bodies like the Office of the Comptroller of the Currency (OCC) demand high transparency in model pipelines, imposing friction on deploying black-box algorithms to production workflows.

Explainable AI (XAI) methods, most notably SHapley Additive exPlanations (SHAP) \cite{lundberg2017unified} and Local Interpretable Model-agnostic Explanations (LIME) \cite{ribeiro2016should}, have emerged as standard tools to bridge this gap. However, financial fraud detection presents a persistent challenge that breaks standard XAI assumptions: extreme class imbalance. In typical credit card datasets, fraud instances constitute less than 1\% of the population \cite{bhattacharyya2011data}. 

When standard XAI methods are applied naively to such imbalanced distributions, they exhibit systematic baseline biases. SHAP, for instance, calculates feature attributions against a background dataset mapping directly to the historical dataset ratio. When this background accurately reflects an imbalanced population (e.g., 99.6\% negative samples), explanations for minority class instances (fraud) become mathematically washed out. The marginal contribution of an anomaly becomes buried beneath the weight of standard operational variance, yielding unhelpful and skewed attributions that fail to satisfy regulators. While some approaches like SMOTE-SHAP or K-Medoids background summarization attempt to address distribution skews, there remains a gap in establishing causal parity between operational demographics and direct transactional features. Furthermore, generating actionable recourse in these spaces requires robust counterfactual baselines. Existing methods like Diverse Counterfactual Explanations (DiCE) \cite{mothilal2020dice} provide solid foundations, but often struggle with the strict continuous optimization boundaries required by high-dimensional financial models.

\section{Related Work}

The challenge of deploying machine learning in finance lies at the intersection of algorithmic fairness, regulatory compliance, and extreme class imbalance. 

\textbf{Explainability under Imbalance.} While SHAP \cite{lundberg2017unified} and LIME \cite{ribeiro2016should} are foundational, their application to imbalanced tabular data often yields distorted attributions. Recent studies highlight that Shapley values heavily depend on the background distribution \cite{aas2021explaining}. When the background is overwhelmingly composed of negative samples (as in fraud detection), demographic priors overshadow anomaly indicators. Research in 2024 has introduced techniques like SHAP-Instance Weighting to adjust model focus on imbalanced data \cite{chen2024shap}, while early 2026 studies warn of a "stability crisis" when standard SHAP is applied naively to highly imbalanced forests \cite{smith2026when}. Approaches like SMOTE-SHAP attempt to balance training sets, but doing so alters the underlying log-odds boundaries. Our IC-SHAP addresses this by calibrating the background data mathematically without distorting the model's predictive margins \cite{fryer2021shapley}.

\textbf{Actionable Recourse and Counterfactuals.} Regulatory frameworks like ECOA mandate that users receive actionable reasons for adverse decisions \cite{wachter2017counterfactual, barocas2020hidden}. Counterfactual explanations provide these pathways. Diverse Counterfactual Explanations (DiCE) \cite{mothilal2020dice} and other generic optimizers \cite{verma2020counterfactual, pawelczyk2020learning} establish baselines. Recent literature has pushed for generating not just valid, but sparse and plausible counterfactuals suitable for credit scoring \cite{dastile2024counterfactual}. However, current frameworks frequently struggle to maintain strictly valid topological constraints (e.g., temporal cyclicality) in high-dimensional domains without generating "impossible" instances \cite{karimi2020algorithmic}. 

\textbf{Concept Drift in Fraud Detection.} Financial behaviors are highly non-stationary. Fraud topologies shift as adversaries adapt, causing rapid model degradation known as concept drift \cite{fiore2024concept}. Traditional cross-validation leaks future knowledge, providing artificially high accuracy. Recent state-of-the-art frameworks integrate XAI to monitor data drift and sequence-based anomalies robustly \cite{wang2025sequential, jones2025explainable}. Our study incorporates strict Out-Of-Time (OOT) validation to measure explainability stability under active adversarial drift.

\subsection{Contributions}

This paper introduces three core contributions:

\begin{enumerate}
    \item \textbf{Imbalance-Calibrated SHAP (IC-SHAP):} A novel modification of SHAP utilizing a strictly balanced background sampling strategy (50\% legitimate, 50\% fraud). This theoretically-grounded calibration corrects systematic bias in explanations while preserving the fundamental anomaly-contrast required for finding boundary cases.
    \item \textbf{Continuous Counterfactual Optimizer (CC-Opt):} An optimization-based counterfactual generator employing continuous L1-norm sparse penalization coupled with firm structural equality constraints. The algorithm guarantees physically realistic actionable derivations, cleanly respecting constraints on immutable features (e.g., age, geographic bounds) while systematically altering dynamic metrics.
    \item \textbf{Explanation Quality Auditor (EQA):} A comprehensive mathematical evaluation framework. Because gradient models produce output natively in Log-Odds space, our EQA forces evaluation back through Sigmoidal scaling mapping directly against non-linear internal boundary metrics, providing robust, true-to-probability tracking.
\end{enumerate}

\section{Methodology}

\subsection{The Imbalance-Aware Explainable Fraud Detection (IAE-FD) Architecture}

The proposed Imbalance-Aware Explainable Fraud Detection (IAE-FD) framework functions as an agnostic interpretability envelope wrapping around any standard black-box classifier. Figure \ref{fig:architecture} illustrates the data and functional workflows of this pipeline.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{architecture.pdf}
\caption{System Architecture of the Imbalance-Aware Explainable Fraud Detection (IAE-FD) Framework, outlining the decoupling of attribution calculations (IC-SHAP), adversarial scenario definitions (RC-CF), and objective probabilistic tracking (EQA) away from the raw predictive models.}
\label{fig:architecture}
\end{figure}

The intelligence framework is defined by the following sequential transformations.

\subsection{Imbalance-Calibrated SHAP (IC-SHAP)}

The traditional Shapley value metric \cite{lundberg2017unified} distributes the outcome payout among features via:
\begin{equation}
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(n-|S|-1)!}{n!} [v(S \cup \{i\}) - v(S)]
\end{equation}

In standard implementations, the expected value baseline $v(S)$ uses a generic background dataset $D$ drawn uniformly from the original sample distributions. In a dataset where legitimate transactions constitute $99.6\%$ of traffic, evaluating fraud cases defaults to explaining ``Why is this anomaly different from a perfectly normal event?'' However, normal events mask extreme ranges of non-fraud bounds, severely diluting specific variables (like transaction amounts).

To solve this, IC-SHAP generates synthetically equivalent evaluation manifolds via two operations:

\textbf{1. Bipartite Separation}: The operational background is split cleanly according to ground truth:
\begin{equation}
D_0 = \{x_i : y_i = 0\}, \quad D_1 = \{x_i : y_i = 1\}
\end{equation}

\textbf{2. 50/50 Calibration Injection}: The background expectation is generated by equalizing prior conditions, forming a perfectly symmetrical baseline mathematically devoid of the demographic density metrics that skew raw predictions:
\begin{equation}
\phi_i^{IC}(f, x) = (0.5 \cdot \phi_i(f, x | D_0)) + (0.5 \cdot \phi_i(f, x | D_1))
\end{equation}

This isolates pure causal relevance without destroying the anomaly contrast.

\subsection{Regulatory-Compliant Counterfactuals (RC-CF)}

A counterfactual explanation posits the minimum set of changes required to invert a model's prediction decision. Mathematically, for an input $x$ classified as fraud ($f(x) \geq \tau$), we seek a counterfactual condition $x'$ such that $f(x') < \tau$. To comply with human legibility (ECOA) rules, the translation delta $\Delta(x, x')$ must be sparse.

We configure an SLSQP optimization sequence resolving against the following objective frontier:
\begin{equation}
\arg\min_{x'} \lambda \cdot \mathcal{L}_{pred}(f(x'), \tau) + \mathcal{L}_{dist}(x, x') + \mathcal{L}_{sparse}(x, x')
\end{equation}

Rather than binary discrete switches which cause zero-gradient stagnation during backpropagation, $\mathcal{L}_{sparse}$ uses an absolute L1 distance proxy penalty, continually pushing dimensions towards zero modification unless actively repelling a prediction score.

Additionally, to prevent absurd physical boundaries like a transaction existing at 25:00 hours, we impose absolute equality restrictions dynamically tying derived matrices back together in loop space, e.g.:
\begin{equation}
x'_{hour\_sin} = \sin\left(\frac{2\pi \cdot x'_{hour}}{24}\right)
\end{equation}

Algorithm \ref{alg:ccopt} formalizes the execution of the CC-Opt framework.

\begin{algorithm}[h]
\caption{Continuous Counterfactual Optimizer (CC-Opt)}\label{alg:ccopt}
\begin{algorithmic}[1]
\Require Black-box model $f$, Original instance $x$, Target threshold $\tau$, Immutable indices $I$, Max iterations $T$
\Ensure Counterfactual $x'$
\State Initialize $x' \gets x + \mathcal{N}(0, \sigma)$ \Comment{Gaussian perturbation avoiding immutable features}
\State Define $\mathcal{L}(x') = \lambda \cdot \max(0, f(x') - \tau) + \alpha \|x' - x\|_2 + \beta \|x' - x\|_1$
\State Define constraints: $\mathcal{C}_{eq} = \{ x'_i = x_i \ \forall i \in I \} \cup \{ \text{Structural equations} \}$
\For{$t = 1$ to $T$}
    \State Compute gradients $\nabla_{x'} \mathcal{L}(x')$ via SLSQP
    \State Update $x'$ respecting bounds and $\mathcal{C}_{eq}$
    \If{$f(x') < \tau$ and convergence criteria met}
        \State \Return $x'$
    \EndIf
\EndFor
\State \Return $x$ \Comment{Return original if optimization fails}
\end{algorithmic}
\end{algorithm}

\subsection{Explanation Quality Auditor (EQA)}

The final component formally judges explanation reliability. Boosted ensembles calculate internal tree gradients relative to log-odds (margin) distances, yet regulators require proof of fidelity in raw probability outputs ($0 \rightarrow 1$). The EQA actively converts raw gradient local outputs back out to probability geometries using a calibrated Sigmoid function:
\begin{equation}
P(y=1) \approx \sigma\left(\mathbb{E}[\text{margin}] + \sum \phi_i^{IC}\right)
\end{equation}
The output from this expression yields a Fidelity Score representing the total correlation rank explaining the accuracy of the local attributions over a random variable walk. 

\section{Experimental Setup}

The operational baseline comprised 555,719 simulated synthetic credit card transactions encoding specific fraud rings, yielding a severe class imbalance of $0.386\%$ frauds. This dataset is sourced from the widely utilized public repository provided by Mittal (2023) \cite{bhattacharyya2011data}, which realistically models adversarial financial behavior. Due to GDPR and proprietary privacy constraints, real-world transaction logs are inaccessible for public research, making high-fidelity synthetic benchmarks the academic standard.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{eda_plots.pdf}
\caption{Exploratory Data Analysis. (A) Extreme class imbalance present in the transactional dataset, plotted on a logarithmic scale. (B) Density plot revealing that fraudulent transactions exhibit a fundamentally different log-amount distribution compared to legitimate operations.}
\label{fig:eda}
\end{figure}

Features were strictly formatted into operational numerics: cyclical features (hour, day of week) converted to $sin/cos$ derivations to preserve spatial proximities, target encoded means utilized for volatile categorical groupings like $job\_enc$ or $merchant\_enc$, and spatial distance calculated via Haversine transformations between customer profiles and point-of-sale origins.

All model splits occurred exclusively via Out-of-Time (OOT) rolling bounds. A standard randomized split (ShuffleSplit) would inadvertently leak future categorical averages.

\section{Results and Discussions}

\subsection{Detection Metrics and Out-of-Time (OOT) Drift}

Traditional evaluation pipelines routinely report artificially inflated bounds on time-series records. When subjected to strict boundary isolation via Time Series Cross Validation (no future look-ahead encoding), the models demonstrated significant performance variance (Figure \ref{fig:model_perf}).

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{model_perf.pdf}
\caption{Overall Model Performance Aggregates. While AUC-ROC runs consistently high across algorithms ($>0.96$), AUC-PRC reveals significant divergence. LightGBM provides optimal precision-recall efficiency.}
\label{fig:model_perf}
\end{figure}

Although LightGBM maximized total Precision-Recall balance ($0.865$), deep chronological validation mapped the true behavioral footprint of the algorithms against concept drift. Figure \ref{fig:oot_drift} illustrates how algorithms behaved sequentially across 5 forward-facing temporal windows.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{oot_drift.pdf}
\caption{OOT Fold progression shows structural decay mapping. LightGBM struggled severely during Fold 1 due to high concept drift (AUC $= 0.542$), whereas Logistic Regression completely ignored categorical drift anomalies (AUC $= 0.872$ to $0.936$).}
\label{fig:oot_drift}
\end{figure}

The severe performance degradation of LightGBM and XGBoost in Fold 1 (AUC $= 0.542$ and $0.673$ respectively) suggests substantial concept drift, particularly in categorical features like \texttt{merchant\_enc}. Tree-based models, which rely heavily on these target-encoded splits, were disproportionately affected by the temporal shift. Contrastingly, Random Forest and classical Logistic Regression remained largely invariant to strict drift partitions, providing significantly higher bounds on generalizing future conditions.

\subsection{Decoupling Feature Importance: SHAP vs IC-SHAP vs LIME}

The most critical contribution of our framework surrounds the elimination of topological biases inherently structured inside generic Explainable AI packages. When investigating transaction profiles, standard SHAP packages are wildly skewed towards macro-demographics ($job\_enc$) simply because they dominate the natural operational space ($99.6\%$ relative scale).

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{feat_imp.pdf}
\caption{Distorted feature priorities: Standard SHAP creates a substantial 29\% attribution gap between generic demographic data ($job\_enc \rightarrow 3.36$) and direct transactional evidence ($amt \rightarrow 2.60$). IC-SHAP geometrically stabilizes these elements pushing them into a functional near-parity ($2.81$ vs $2.70$).}
\label{fig:feat_imp}
\end{figure}

As quantified in Figure \ref{fig:feat_imp}, conventional extraction produces a skewed narrative: the algorithm heavily isolates abstract metadata simply because it contrasts well against massive swaths of legitimate backgrounds. 

When replacing standard SHAP with our IC-SHAP, the 50/50 target calibration neutralizes the generic background variance. It is critical to note that while standard SHAP accurately explains the \textit{global model reliance} (the model genuinely uses demographics to isolate anomalies because the data is 99.6\% legitimate), IC-SHAP calculates \textit{conditional feature importance}. By artificially suppressing the demographic variance of the majority class, IC-SHAP mathematically drives the raw transaction quantity (\texttt{amt}) directly back to the surface as a premier causal boundary feature. This does not represent how the model naturally operates over the full distribution; rather, it represents the specific causal drivers separating a fraudster from a perfectly equivalent legitimate user, improving algorithmic accountability metrics by aligning closely with established financial investigation logic.

To illustrate this effect at the instance level, Figure \ref{fig:local_shap} demonstrates the attribution shift for a single, highly anomalous transaction. While Standard SHAP masks the fraudulent \texttt{amt} behind the sheer density of the user's demographic profile (\texttt{job\_enc}), IC-SHAP correctly unmasks the monetary amount as the primary causal driver of the anomaly.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{local_shap.pdf}
\caption{Local Explanation Shift for a single transaction (Instance \#1064). Standard SHAP over-attributes the prediction to the demographic \texttt{job\_enc} due to its prevalence in the background data. IC-SHAP recalibrates the baseline, correctly unmasking the extreme transaction \texttt{amt} as the primary causal factor driving the fraud classification.}
\label{fig:local_shap}
\end{figure}

It is additionally critical to exclude methods like LIME from fraud topologies. Analysis of experimental logs revealed that LIME identified tangential properties (\texttt{cat\_gas\_transport}) as its top vector constraint, almost inherently ignoring \texttt{amt} completely with an importance score of effectively $0.019$. LIME is structurally incapable of processing extreme sparse boundaries correctly.

\subsection{Ablation Studies on Background Calibration}

To verify why breaking down the calibration explicitly into binary halves was necessary, we performed an ablation study disabling individual components of IC-SHAP.

\begin{table}[h]
\centering
\caption{Ablation Impact on Explanation Signal Smoothing}
\label{tab:ablation}
\begin{tabular}{llc}
\toprule
\textbf{Methodology Bounds} & \textbf{Dominant Signal Extraction} & \textbf{Mean Baseline Signal} \\
\midrule
Standard Native SHAP        & job\_enc    & 0.373  \\
Stratified Background Only  & job\_enc    & 0.147  \\
Constant Weight Approx.     & job\_enc    & 0.373  \\
\textbf{Full Native IC-SHAP}& \textbf{job\_enc (\& amt approaching parity)}    & \textbf{0.334}  \\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:ablation} shows that merely stratifying the background reduces overall signal volume down to noise ($0.147$), failing to produce active boundaries. Only when both partitions and weights are geometrically bound tightly does the final attribution smooth safely into a usable scale ($0.334$).

\subsection{Explanation Quality Assessment (Fidelity \& Stability)}

Using the Evaluation Quality Auditor matrix, we ran independent permutations tracking correlation against mathematical distributions. 

While Standard SHAP achieved perfect fidelity ($1.000$) and high stability ($0.927$), IC-SHAP introduces a necessary trade-off. IC-SHAP yielded a fidelity of $0.966$ and stability of $0.854$. This degradation in mathematical stability is a documented compromise to correct the severe demographic bias in feature attributions, aligning the explanations with actual transactional causality rather than generic population densities. Both methods required 16 features to cover 95\% of the variance, confirming that comprehensibility was unaffected.

\subsection{Regulatory Counterfactual Optimization Outputs}

A core demand of regulatory systems relies on providing consumers with understandable pathways upon rejection. In financial boundaries, explanations must be minimal, comprehensible, and strictly mathematically possible. Our CC-Opt module proved successful against adversarial gradients while rigidly maintaining structural constraints.

To establish a baseline, we deployed the industry-standard Diverse Counterfactual Explanations (DiCE) \cite{mothilal2020dice} framework utilizing a random sampling generation method across the same 50 highly anomalous fraud instances. The DiCE baseline achieved a 100\% success rate with an average sparsity of only \textbf{1.74 feature changes}. However, this extreme sparsity was achieved by violating the physical constraints of the dataset. For example, DiCE routinely modified the raw transaction amount (\texttt{amt}) without simultaneously updating its dependent logarithmic transformation (\texttt{amt\_log}), or altered the cyclical \texttt{hour} without updating the corresponding \texttt{hour\_sin} and \texttt{hour\_cos} embeddings. Such counterfactuals represent "impossible" adversarial points in the feature space.

In contrast, our CC-Opt optimizer enforces strict structural equality constraints dynamically during backpropagation. Over the test suite, CC-Opt yielded a \textbf{100\% success rate} in resolving paths out of fraud probabilities. However, respecting the mathematical reality of the data required modifications to an average of \textbf{14.6 variables}. Figure \ref{fig:cf_changes} illustrates the distribution of required feature modifications to achieve recourse under these strict topological bounds.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{cf_changes.pdf}
\caption{Distribution of feature modifications required to generate successful counterfactuals. The high mean indicates the difficulty of achieving sparse recourse in this domain.}
\label{fig:cf_changes}
\end{figure}

\begin{table}[h]
\centering
\caption{Empirical Output: RC-CF Escaping Probability Confidence Rings}
\label{tab:cfs}
\begin{tabular}{cccl}
\toprule
\textbf{Transaction ID} & \textbf{Initial Prediction $\rightarrow$ Goal Prediction} & \textbf{Active Deltas} & \textbf{Key Features Mutated} \\
\midrule
696 & \textbf{0.999} $\rightarrow$ 0.470 & 21  & amt, hour, hour\_cos, \dots \\
1064 & \textbf{0.999} $\rightarrow$ 0.026 & 24 & amt, hour, hour\_sin, hour\_cos \\
2136 & \textbf{0.991} $\rightarrow$ 0.087 & 1 & merchant\_enc \\
5268 & \textbf{0.999} $\rightarrow$ 0.0001 & 22 & amt, amt\_log, hour, hour\_sin \\
\bottomrule
\end{tabular}
\end{table}

As noted in Table \ref{tab:cfs}, events classified natively at $0.999$ confidence limits were efficiently mapped backward leveraging continuous structures minimizing arbitrary shifts. Instance 2136 demonstrates that changing merely $1$ feature (`merchant\_enc`) substantially reduced the classification from $0.991$ to $0.087$. 

While a 100\% success rate demonstrates the optimizer's capability to cross decision boundaries, an average of 14.6 feature changes out of 27 indicates that escaping the fraud classification for highly anomalous transactions requires extensive alterations. This presents a practical challenge for regulatory compliance, where actionable recourse ideally involves sparse, achievable modifications. Future work must better balance L1 regularization with structural constraints to enforce stricter sparsity.

\section{Conclusion}

Financial systems mandate transparent operations devoid of algorithmic prejudice. The generic formulation of Explainable AI networks fundamentally collapses under imbalanced density distributions, yielding severely corrupted causal pathways that emphasize demographics locally over actual behavioral indicators. 

By restructuring evaluations mapping directly into Imbalance-Calibrated partitions coupled strictly with continuous differentiable counterfactuals, this paper presented a holistic resolution. The IAE-FD framework delivers operational intelligence, robust performance via Out-Of-Time drift bounds, and strict topological metrics achieving boundary counterfactual compliance. These tools reduce algorithmic liability, enabling robust, fully interpretable fraud systems across enterprise financial operations.

\textbf{Limitations and Future Work.} While CC-Opt successfully generates recourse respecting the mathematical reality of the data, the requirement to modify an average of 14.6 features highlights a profound limitation in achieving truly actionable recourse in high-dimensional financial spaces. Future research must investigate localized manifold learning techniques or constrained generative models (e.g., Variational Autoencoders) to discover lower-dimensional, highly sparse pathways for recourse without violating strict structural equalities.

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}